{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install -q sentence-transformers\n",
    "# !pip install ragas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "190d7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb40bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# --- Load API Key ---\n",
    "load_dotenv(override=True)\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6571c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Retriever: Get top-k docs ---\n",
    "def get_top_k_similar(query, k=3):\n",
    "    documents = [\n",
    "        {\"section\": \"Pay Policies\", \"content\": \"Employees are paid bi-weekly via direct deposit.\"},\n",
    "        {\"section\": \"Leave of Absence\", \"content\": \"Employees must submit a leave request for approval.\"},\n",
    "        {\"section\": \"Internet Use\", \"content\": \"Company internet must be used for work-related tasks only.\"}\n",
    "    ]\n",
    "\n",
    "    texts = [doc[\"content\"] for doc in documents]\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    doc_vectors = model.encode(texts, convert_to_tensor=True)\n",
    "    query_vec = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    similarities = util.cos_sim(query_vec, doc_vectors)[0].cpu().numpy()\n",
    "    top_k_idx = np.argsort(similarities)[::-1][:k]\n",
    "\n",
    "    return [documents[int(idx)] for idx in top_k_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9415ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- Generator: Use OpenAI with retrieved docs ---\n",
    "def generate_answer(query, contexts):\n",
    "    context_text = \" \".join(contexts)\n",
    "    prompt = f\"Answer the question based only on the following context:\\n{context_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # or gpt-3.5-turbo\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ccb7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build dataset for Ragas ---\n",
    "def build_dataset():\n",
    "    query = \"How often do employees get paid?\"\n",
    "    retrieved_docs = get_top_k_similar(query, 3)\n",
    "    contexts = [d[\"content\"] for d in retrieved_docs]\n",
    "\n",
    "    # Gold reference\n",
    "    gold_answer = \"Employees are paid bi-weekly via direct deposit.\"\n",
    "\n",
    "    # Generate answer using LLM\n",
    "    model_answer = generate_answer(query, contexts)\n",
    "\n",
    "    examples = [\n",
    "        {\n",
    "            \"question\": query,\n",
    "            \"answer\": model_answer,        # LLM-generated answer\n",
    "            \"contexts\": contexts,         \n",
    "            \"reference\": gold_answer,     \n",
    "            \"ground_truths\": [gold_answer]\n",
    "        }\n",
    "    ]\n",
    "    return Dataset.from_list(examples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53c16149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Full RAG Evaluation Results\n",
      "{'context_recall': 1.0000, 'context_precision': 1.0000, 'faithfulness': 1.0000, 'answer_correctness': 0.7408, 'answer_similarity': 0.9632}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = build_dataset()\n",
    "\n",
    "# --- All metrics across retriever, generator, and end-to-end ---\n",
    "all_metrics = [\n",
    "    context_recall, context_precision,  # Retriever\n",
    "    \n",
    "    faithfulness, answer_correctness, answer_similarity  # Generator\n",
    "\n",
    "]\n",
    "\n",
    "results = evaluate(dataset, metrics=all_metrics)\n",
    "\n",
    "print(\"\\nðŸ”¹ Full RAG Evaluation Results\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b147606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Full RAG Evaluation Results (Aggregated)\n",
      "{'context_recall': 1.0000, 'context_precision': 1.0000, 'faithfulness': 1.0000, 'answer_correctness': 0.7417, 'answer_similarity': 0.9666}\n",
      "\n",
      "ðŸ”¹ Detailed Scores (per question & metric)\n",
      "\n",
      "Q1: How often do employees get paid?\n",
      "  Answer: Employees are paid bi-weekly.\n",
      "  Ground Truth: Employees are paid bi-weekly via direct deposit.\n",
      "  Contexts: ['Employees are paid bi-weekly via direct deposit.', 'Employees must submit a leave request for approval.', 'Company internet must be used for work-related tasks only.']\n",
      "Example 1 | context_recall: 1.000\n",
      "Example 1 | context_precision: 1.000\n",
      "Example 1 | faithfulness: 1.000\n",
      "Example 1 | answer_correctness: 0.742\n",
      "Example 1 | answer_similarity: 0.967\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset()\n",
    "\n",
    "# --- All metrics across retriever, generator, and end-to-end ---\n",
    "all_metrics = [\n",
    "    context_recall, context_precision,      # Retriever\n",
    "    faithfulness, answer_correctness, answer_similarity  # Generator\n",
    "]\n",
    "\n",
    "results = evaluate(dataset, metrics=all_metrics)\n",
    "\n",
    "print(\"\\nðŸ”¹ Full RAG Evaluation Results (Aggregated)\")\n",
    "print(results)\n",
    "\n",
    "# --- Show detailed per-example breakdown ---\n",
    "print(\"\\nðŸ”¹ Detailed Scores (per question & metric)\")\n",
    "for i, row in enumerate(dataset):\n",
    "    print(f\"\\nQ{i+1}: {row['question']}\")\n",
    "    print(f\"  Answer: {row['answer']}\")\n",
    "    print(f\"  Ground Truth: {row['reference']}\")\n",
    "    print(f\"  Contexts: {row['contexts']}\")\n",
    "    \n",
    "    # Each metric is a column in `results` matching the dataset rows\n",
    "for metric in all_metrics:\n",
    "    metric_name = metric.name  # âœ… use the metric's internal name\n",
    "    scores = results[metric_name]\n",
    "    for i, score in enumerate(scores):\n",
    "        print(f\"Example {i+1} | {metric_name}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016d252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
